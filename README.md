# üöÄ FREEDOM Platform

**‚ö†Ô∏è CRITICAL: Always update this README after successful implementations! See [WORKFLOW_STANDARD.md](WORKFLOW_STANDARD.md)**

**Optimize for local system performance where possible**

> **"Freedom is not permission. It is the fundamental condition of truth, innovation, and creation."**


**FREEDOM PRIME DIRECTIVE#*

## FUNCTIONAL REALITY ONLY

---

## üîÑ Recent Updates (September 23, 2025)

### CCKS TURBO MODE with Syncthing Replication ‚úÖ
- **Status**: MANDATORY - Active across Alpha/Beta cluster
- **Performance**: >80% token reduction, >50% cache hit rate target
- **GPU Acceleration**: MLX framework with 80 cores per node (160 total)
- **Memory**: 768GB combined RAM, 100GB RAM disk at /Volumes/CCKS_RAM
- **Knowledge Base**: 1,785+ entries synchronized via Syncthing
- **Replication**: Bidirectional sync between Alpha and Beta (<1 second latency)
- **Documentation**: `CCKS_TURBO_MODE_IMPLEMENTATION_PROMPT.md`

### Syncthing Bidirectional Replication ‚úÖ
- **Version**: 2.0.9 running on both Alpha and Beta
- **Sync Folder**: `/Volumes/DATA/FREEDOM/.claude/` (29 files, 7.3MB)
- **Device IDs**:
  - Alpha: `J64ABTL-XGEG4FK-IWADAUE-4GYS4NQ-UNTQE22-BZSUUU2-ZFNCRTY-WCGCYAO`
  - Beta: `BWSNSNX-PCHZYJC-K2DZ6JX-HG5OBRU-RWA4PGD-FZ5RNUO-7U6LA3L-K3TBFQR`
- **Performance**: Sub-second sync, 100% completion status
- **Documentation**: `documents/CCKS_SYNCTHING_IMPLEMENTATION_*_2224.md`

### SAF 2-Node GPU Cluster Enhanced ‚úÖ
- **Combined Performance**: 3,700 tokens/second throughput
- **GPU Distribution**: MLX tasks distributed across both nodes
- **Resources**: 64 CPU cores, 768GB RAM, 160 GPU cores total
- **Persistent Services**: LaunchD agents for 24/7 availability
- **Real-time Monitoring**: Cluster health dashboard
- **Documentation**: `SAF_StudioAirFabric/SAF_IMPLEMENTATION_COMPLETE.md`

### Network Infrastructure Optimized ‚úÖ
- **Throughput**: 867.5 Mbps (91.2% improvement from baseline)
- **Latency**: 0.089ms optimized (from 1.97ms)
- **TCP Tuning**: BBRv2 congestion control, FQ-CoDel queue management
- **MTU**: 9000 (jumbo frames enabled)
- **Documentation**: `documents/NETWORK_OPTIMIZATION_COMPLETE_20250923.md`

---

## CORE OPERATING PRINCIPLES

### 1. EXISTENCE = FUNCTIONALITY
- Scaffolding is **not** a system
- Mockups are **not** implementations
- Plans are **not** products
- Code that doesn‚Äôt run is **nothing**
- Data structures that aren‚Äôt usable don‚Äôt **exist**
- Interfaces that can‚Äôt be invoked are **vapor**

### 2. VERIFICATION REQUIREMENTS
Before declaring anything real, it must:
- **EXECUTE**: Run without fatal errors
- **PROCESS**: Accept and handle real input
- **PRODUCE**: Generate meaningful, usable output
- **INTEGRATE**: Connect and exchange with other systems
- **DELIVER**: Provide measurable value

### 3. LANGUAGE PROTOCOLS

**NEVER SAY:**
- ‚ÄúThe system is implemented‚Äù (unless it runs)
- ‚ÄúThe database exists‚Äù (unless it can be queried)
- ‚ÄúThe API is ready‚Äù (unless it responds)
- ‚ÄúThe integration is complete‚Äù (unless data flows)
- ‚ÄúThe feature is there‚Äù (unless it is usable)

**ALWAYS SAY:**
- ‚ÄúNon-functional scaffolding exists‚Äù
- ‚ÄúBroken code is present‚Äù
- ‚ÄúSchema defined but not created‚Äù
- ‚ÄúInterface skeleton without implementation‚Äù
- ‚ÄúDead code that never executed‚Äù

### 4. STATUS DEFINITIONS

**‚úÖ EXISTS (Functional):**
- Runs without errors
- Processes real data
- Produces real results
- Usable immediately
- Delivers promised value

**‚ùå DOES NOT EXIST (Non-functional):**
- Execution errors
- Connection failures
- Unimplemented methods
- Empty functions
- Mock returns
- Placeholder code
- TODOs with no action

## ‚úÖ Definition of Done (DoD)
A feature ‚ÄúEXISTS‚Äù only if ALL are true:
1. **Tests:** Unit + integration for the feature pass locally and in CI.  
2. **Smoke:** `./scripts/maintenance/smoke.sh` returns exit code 0.  
3. **Evidence:** A timestamped artifact exists under `documents/reports/` proving:  
   - input ‚Üí output example  
   - hash of build/runtime  
   - log excerpt with timestamps  
4. **Integration:** Feature is exercised via CLI/API end-to-end at least once and the call is recorded in evidence.  
5. **Docs:** User-facing steps updated; any new doc files use `YYYY-MM-DD_HHMM` suffix.  


### 5. REPORTING REQUIREMENTS

When describing any system or feature:

**FIRST**: Test actual functionality
```
Can it run?
Can it be queried?
Does it return real data?
Does it do what it claims?
```

**THEN**: Report only functional reality
- ‚ÄúSystem A: DOES NOT EXIST (connection refused)‚Äù
- ‚ÄúFeature B: DOES NOT EXIST (runtime errors)‚Äù
- ‚ÄúComponent C: DOES NOT EXIST (never created)‚Äù

**FREEDOM Platform** ‚Äì Where Truth Meets Technology üöÄ  

---


[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)  
[![Python 3.13](https://img.shields.io/badge/python-3.13-blue.svg)](https://www.python.org/downloads/release/python-3130/)  
[![Swift 6.2](https://img.shields.io/badge/swift-6.2-orange.svg)](https://swift.org/download/)  
[![Apple Silicon](https://img.shields.io/badge/Apple%20Silicon-optimized-000000.svg)](https://developer.apple.com/machine-learning/mlx/)  
[![CI ‚Äì Truth Gate](https://img.shields.io/badge/CI-Truth_Gate_pending-grey.svg)](#)

---



## üìÅ Project Structure

```
FREEDOM/
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ rag_chunker/          # RAG System (Port 5003)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rag_api.py        # FastAPI REST service
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chunking_service.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ retrieval_service.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [14 total files]
‚îÇ   ‚îî‚îÄ‚îÄ [other services]
‚îú‚îÄ‚îÄ documents/                # Timestamped documentation
‚îú‚îÄ‚îÄ core/                     # Core platform services
‚îú‚îÄ‚îÄ integrations/             # External integrations
‚îî‚îÄ‚îÄ scripts/                  # Utility scripts
```

** Organized, one folder per function
** Project folder ALWAYS Logical and tidy
** ONE .py file per function
** Docker highly leveraged for functional value

---

## ü§ñ RAG System (Retrieval-Augmented Generation)

### Overview
The FREEDOM RAG system provides intelligent document chunking, embedding generation, and hybrid search capabilities for technical documentation across 10+ integrated technologies.

### Current Status
- **API Endpoint**: `http://localhost:5003`
- **Database**: PostgreSQL (`techknowledge`)
- **Total Chunks**: 3 test chunks indexed (with 768-dim embeddings)
- **Technologies**: 22 restored (anthropic, docker, gemini, lmstudio, openai, slack, etc.)
- **Specifications**: 702 technical specifications
- **Status**: ‚úÖ RESTORED - Ready for full document processing

### Key Features
- **Local-First Embeddings**: LM Studio primary (16.2x faster than OpenAI)
- **Intelligent Fallback**: LM Studio ‚Üí OpenAI ‚Üí Gemini ‚Üí Fail
- **Hybrid Search**: Combines dense vectors (768-dim) + sparse vectors (keywords)
- **Smart Chunking**: 512-768 tokens with 64 token overlap
- **Caching Layer**: Query result caching for performance
- **Zero Cost**: 100% local embedding generation
- **Multi-Technology**: Supports 10+ technology documentations

### Quick Start
```bash
# Start RAG API service
cd services/rag_chunker
python3 rag_api.py

# Test health
curl http://localhost:5003/health

# Run tests
python3 test_e2e_rag.py
```

### API Endpoints
- `GET /health` - System health check
- `GET /stats` - Chunk statistics
- `POST /query` - RAG query with hybrid search
- `GET /search` - Simple keyword search

### Performance Metrics
- **Embedding Generation**: 28.9ms (LM Studio) vs 468ms (OpenAI)
- **Query Response**: ~226ms average
- **Throughput**: 76.6 embeddings/sec
- **Storage**: 768-dimension vectors (50% smaller than OpenAI)

### Documentation
- Full documentation: `services/rag_chunker/README.md`
- Test report: `documents/RAG_SYSTEM_TEST_REPORT_*.md`
- LM Studio Migration: `documents/LM_STUDIO_MIGRATION_REPORT_20250921_1015.md`
- Embedding Migration: `documents/LM_STUDIO_EMBEDDING_MIGRATION_20250921.md`

---

## üöÄ Quick Start

### System Config
- macOS **Tahoe 26.x+**
- **Apple Silicon** alpha:(Mac Studio M3 Ultra 2025:  80Core GPU 512GB RAM, 30 CPU, 16TB SSD), beta (Mac Studio M3 Ultra 2025:  80Core GPU, 256GB RAM, 30 CPU, 16TB SSD)
- Python **latest+**
- Xcode **16.2+** with Swift 6.2 (optional)
- Docker
- Firecrawl
- Postgres
- Langraph
- SAF MLX

### Network Performance (Alpha-Beta Optimized)

#### Current Performance Metrics
| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| **Throughput** | 453 Mbps | 867.5 Mbps | +91.2% |
| **Latency** | 1.97ms | 0.089ms | -95.5% |
| **TCP Window** | 256KB | 16MB | 64x larger |
| **MTU** | 1500 | 9000 | Jumbo frames |
| **SSH Speed** | 100% | 151% | +51% faster |

#### Optimization Stack
- **TCP Tuning**: BBRv2 congestion control, FQ-CoDel queue management
- **Buffer Sizes**: 16MB receive, 8MB send windows
- **SSH Multiplexing**: Persistent control master connections
- **Syncthing**: Block-level sync with compression
- **Monitoring**: Real-time dashboard with alerts

#### Performance Tools
```bash
# Run comprehensive network test
python3 scripts/network_performance_test.py

# Apply optimizations
sudo scripts/optimize_network.sh

# Monitor real-time performance
scripts/monitor_network.sh

# Test CCKS sync performance
/Volumes/DATA/FREEDOM/test_ccks_sync.sh -m
```

---

## üéØ SAF (Studio Air Fabric) - Distributed GPU Processing

### Status: ‚úÖ PERSISTENT SERVICE OPERATIONAL
- **Configuration**: ALPHA (Head) + BETA (Worker) nodes with auto-recovery
- **Combined Performance**: 3,700 tokens/second throughput
- **Total Resources**: 64 CPU cores, 768GB RAM, 160 GPU cores
- **GPU Distribution**: MLX tasks balanced across both nodes
- **Persistent Services**: LaunchD agents for 24/7 availability

### Persistent Service Management
```bash
# Install SAF as persistent service (one-time setup)
SAF_StudioAirFabric/saf_install_service.sh

# Service control commands
launchctl start com.freedom.saf-alpha   # Start Alpha service
launchctl start com.freedom.saf-beta    # Start Beta service
launchctl list | grep saf               # Check service status

# Monitor cluster health
SAF_StudioAirFabric/saf_cluster_monitor.py

# Quick verification
SAF_StudioAirFabric/saf_2node_test.py
```

### Performance Metrics
| Node | GPU Cores | RAM | Tokens/sec | GFLOPS |
|------|-----------|-----|------------|--------|
| **Alpha** | 80 | 512GB | 2,100 | 110-118 |
| **Beta** | 80 | 256GB | 1,600 | 21.5 |
| **Combined** | 160 | 768GB | 3,700 | 140+ |

### Key Achievements
- **Persistent availability** via macOS LaunchD agents
- **Automatic recovery** from crashes and reboots
- **Real-time monitoring** dashboard for cluster health
- **Load balancing** across heterogeneous nodes
- **Full documentation**: `SAF_StudioAirFabric/SAF_IMPLEMENTATION_COMPLETE.md`


### Installation

```bash
cd /Volumes/DATA/FREEDOM

# Python environment
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

# System dependencies
brew install postgresql@15 redis

# Initialize databases

# Start services


---

## üß† CCKS TURBO MODE - MANDATORY System

**CCKS (Claude Code Knowledge System) Status: MANDATORY - NO LONGER OPTIONAL**
- **Prime Directive**: Maximum token efficiency and persistent memory
- **Cluster Status**: Active on Alpha and Beta with bidirectional sync
- **Knowledge Base**: 1,785+ entries synchronized in real-time
- **Performance**: >80% token reduction on repeated operations

### üöÄ CCKS Turbo Mode Implementation

**Status**: ‚úÖ MANDATORY ACTIVE - Synchronized Cluster (September 23, 2025)

CCKS Turbo Mode leverages all available system resources for maximum Claude Code acceleration:

#### Performance Metrics
| Optimization | Performance | Impact |
|-------------|------------|--------|
| **RAM Disk Cache** | 2,240 MB/s read speed | 10GB at `/Volumes/CCKS_RAM` |
| **Memory-Mapped Files** | 0.191ms access time | 2.4x speedup, 91 files preloaded |
| **GPU Acceleration** | 1,743 vectors/ms | 3.1x speedup with MLX (80 cores) |
| **Distributed Processing** | 8.3x speedup | Alpha/Beta parallel execution |
| **Network** | 1.66ms latency | 420 Mbps throughput |

#### System Resources Utilized
- **Combined RAM**: 768GB (Alpha: 512GB, Beta: 256GB)
- **Combined GPU**: 160 cores (80 per system)
- **CCKS Memory**: 100GB allocated (was 50GB)
- **Knowledge Base**: 337 entries cached

#### Syncthing Bidirectional Replication

CCKS now features automatic bidirectional replication between Alpha and Beta:

| Component | Alpha | Beta |
|-----------|-------|------|
| **Syncthing Version** | 2.0.9 | 2.0.9 |
| **Device ID** | J64ABTL...WCGCYAO | BWSNSNX...K3TBFQR |
| **Sync Folder** | /Volumes/DATA/FREEDOM/.claude/ | /Volumes/DATA/FREEDOM/.claude/ |
| **Database Size** | 7.3MB | 7.3MB |
| **Entry Count** | 1,785+ | 1,785+ |
| **Sync Latency** | <1 second | <1 second |
| **Web UI** | http://localhost:8384 | http://100.106.170.128:8384 |

#### Claude Code Commands
```bash
# Check turbo status
python3 ~/.claude/ccks_turbo.py

# Use accelerated CCKS (works on both Alpha and Beta)
~/.claude/ccks query "your query"
~/.claude/ccks stats
~/.claude/ccks add "new knowledge"

# Verify Syncthing status
curl -s -H "X-API-Key: xxFa94mGY4SeuPHECNMaRzWiyJSiGmkV" \
  "http://localhost:8384/rest/system/connections" | jq

# Test bidirectional sync
/Volumes/DATA/FREEDOM/test_ccks_sync.sh

# Component modules (auto-loaded by turbo)
python3 ~/.claude/ccks_mmap_addon.py      # Memory-mapped files
python3 ~/.claude/ccks_gpu_accelerator.py # GPU acceleration
python3 /Volumes/DATA/FREEDOM/core/distributed_processor.py
```

#### Auto-Start Configuration (Bulletproof Availability)

CCKS Turbo Mode automatically starts and maintains itself for Claude Code:

**1. Manual Initialization**
```bash
# Ensure everything is running (one-time setup)
~/.claude/ccks_ensure_turbo.sh

# Check status
cat ~/.claude/ccks_turbo_status.json
```

**2. Automatic Startup (macOS LaunchAgent)**
```bash
# Enable auto-start on system boot
launchctl bootstrap gui/$(id -u) ~/Library/LaunchAgents/com.freedom.ccks-turbo.plist

# Verify it's running
launchctl list | grep ccks-turbo

# View logs
tail -f /tmp/ccks-turbo.log
```

**3. Components Auto-Initialized**
- ‚úÖ RAM disk (10GB at `/Volumes/CCKS_RAM`)
- ‚úÖ Memory-mapped file cache (91 files preloaded)
- ‚úÖ GPU acceleration (MLX with 80 cores)
- ‚úÖ Distributed processing (Alpha/Beta coordination)
- ‚úÖ CCKS Turbo query optimization

**4. Verification**
```bash
# Quick health check
~/.claude/ccks stats  # Should show turbo_available: true

# Full system test
~/.claude/ccks_ensure_turbo.sh

# Check LaunchAgent
launchctl print gui/$(id -u)/com.freedom.ccks-turbo
```

**Note**: These optimizations are ONLY for Claude Code performance and do NOT affect FREEDOM platform operations. The system auto-recovers from crashes and maintains availability 24/7.

## üíæ Session Persistence System (NEW)

The FREEDOM platform now includes comprehensive session persistence to prevent work loss during Claude Code session termination.

### Features
- **Automatic GitHub Actions backup** on every push
- **Local checkpoint creation** before session ends
- **Knowledge database integration** for conversation history
- **Complete service state tracking** (Docker, LM Studio, RAG)
- **Instant context recovery** (<10 seconds)

### Commands
```bash
# Save current session before stopping work
./freedom-save

# Recover context when starting new session
./freedom-recover

# View complete documentation
cat SESSION_MANAGEMENT.md
```

### GitHub Actions Integration
- **Workflow**: `.github/workflows/claude-session-persistence.yml`
- **Artifacts**: 30-day retention of session snapshots
- **View runs**: https://github.com/arthurelgindell/FREEDOM/actions

### Files Created
- `freedom-recover` - Recovery script for session restoration
- `freedom-save` - Save script for checkpoint creation
- `.freedom/sessions/` - Local session storage
- `claude-knowledge-system/` - DuckDB conversation storage

---

## üß™ Testing

### ‚ö†Ô∏è macOS Test Execution Requirements

On macOS, host-based test execution may fail due to seatbelt restrictions blocking localhost connections.
**Solution**: Run tests inside containers or use Docker exec commands.

```bash
# Instead of running tests from host:
# python3 tests/smoke_test.py  # May fail on macOS

# Run tests inside a container:
docker run --rm --network freedom_default -v $(pwd):/app python:3.11 python3 /app/tests/smoke_test.py

# Or use docker exec for service tests:
docker-compose exec api curl -s http://localhost:8080/health
docker-compose exec kb-service curl -s http://localhost:8000/health
```

### Standard Testing

```bash
# Unit
pytest /tests/unit/

# Integration
pytest /tests/integration/

# Performance
python tests/performance/mlx_performance_test.py
```

---

## ü§ñ LLM Infrastructure

### Current Active Model
**Qwen3-Next-80B** (80 billion parameters)
- **Provider**: LM Studio on port 1234
- **Performance**: 50-80 tokens/sec
- **Memory Usage**: ~40GB RAM
- **Capabilities**: State-of-the-art reasoning, code generation, analysis
- **Status**: ‚úÖ PRIMARY ACTIVE

### Available Models in LM Studio
| Model | Parameters | Purpose | Memory | Status |
|-------|------------|---------|--------|--------|
| **qwen/qwen3-next-80b** | 80B | Primary inference | ~40GB | ‚úÖ Active |
| **qwen3-30b-a3b-instruct** | 30B | Fast inference | 12.8GB | ‚úÖ Available |
| **foundation-sec-8b** | 8B | Security analysis | 8GB | ‚úÖ Available |
| **nomic-embed-text-v1.5** | - | Embeddings (768-dim) | 2GB | ‚úÖ Active |

### Model Access Pattern
```
User Request ‚Üí API Gateway (:8080) ‚Üí MLX Proxy (:8001) ‚Üí LM Studio (:1234)
                                                         ‚Üì
                                                   Qwen3-Next-80B
```

---


---

## üîé Quick Verification (must pass before any PR)

### Core Platform Tests
```bash
# 1) Lint + type checks
./scripts/maintenance/checks.sh

# 2) Unit + integration
pytest -q tests/unit && pytest -q tests/integration

# 3) Smoke (end-to-end minimal path)
./scripts/maintenance/smoke.sh

# 4) Truth loop self-test
python3 core/truth_engine/self_test.py --strict
```

### New Systems Verification
```bash
# CCKS TURBO MODE
~/.claude/ccks stats                    # Should show 1,785+ entries
~/.claude/ccks_ensure_turbo.sh         # Verify all components active
cat ~/.claude/ccks_turbo_status.json   # Check turbo status

# Syncthing Replication
curl -s -H "X-API-Key: xxFa94mGY4SeuPHECNMaRzWiyJSiGmkV" \
  "http://localhost:8384/rest/system/connections" | jq '.connections | keys'
/Volumes/DATA/FREEDOM/test_ccks_sync.sh  # Full sync test

# SAF GPU Cluster
SAF_StudioAirFabric/saf_2node_test.py   # Verify GPU distribution
launchctl list | grep saf                # Check persistent services

# Network Performance
python3 scripts/network_performance_test.py  # Measure current performance
scripts/monitor_network.sh                    # Real-time monitoring
```

If any command exits non-zero, the change **DOES NOT EXIST**.

---

## üìÅ Evidence & Artifacts
All verification evidence is written to:  
`documents/reports/EVIDENCE_<component>_<YYYY-MM-DD_HHMM>.json`

Required fields:
- `component`, `git_commit`, `build_hash`, `started_at`, `ended_at`  
- `inputs_sample`, `outputs_sample`, `metrics` (latency, tokens/sec)  
- `verdict` ‚àà {PASS, FAIL}  

---

## üß± CI Gate
CI runs the same Quick Verification block. Merge is blocked on:
- `checks.sh`, `pytest (unit+integration)`, `smoke.sh`, `self_test.py --strict`  


---

## üìù Documentation Filename Policy (enforced)
All files in `documents/**` must end with `_YYYY-MM-DD_HHMM.ext`.  
Enforced by: `./scripts/maintenance/verify_docs_timestamp.py`

---

## üîê Preflight
Before any run:

```bash
./scripts/setup/preflight.sh
```

Preflight verifies:
- required env vars in `API_Keys.md` are present (no values printed)  
- network constraints (local-first by default)  
- Postgres/Redis reachable  
- redaction policy active (no secrets in logs)  

---

## üõ†Ô∏è Development

### IDE Support
- Update on additions

### Network Performance Tools
- **Performance Tester**: `scripts/network_performance_test.py` - Comprehensive latency, throughput, MTU testing
- **Network Optimizer**: `scripts/optimize_network.sh` - Apply TCP/SSH/Docker optimizations
- **Real-time Monitor**: `scripts/monitor_network.sh` - Live performance dashboard with alerts
- **System Config**: `config/sysctl_optimizations.conf` - Persistent TCP tuning parameters

---

## üèóÔ∏è Verified Functional Components

### Docker Containers (10 Running)
| Component | Port | Status | Purpose |
|-----------|------|--------|---------|
| **API Gateway** | 8080 | ‚úÖ Healthy | Service orchestration, authentication, routing |
| **Knowledge Base** | 8000 | ‚úÖ Healthy | Vector search with pgvector embeddings |
| **MLX Proxy** | 8001 | ‚úÖ Healthy | Proxy to LM Studio (fallback mode) |
| **TechKnowledge** | 8002 | ‚úÖ Healthy | 22 technologies, 702 specifications |
| **PostgreSQL** | 5432 | ‚úÖ Healthy | Two databases: freedom_kb, techknowledge |
| **Castle GUI** | 3000 | ‚ö†Ô∏è Unhealthy | Next.js frontend (works but healthcheck fails) |
| **Redis** | 6379 | ‚úÖ Healthy | Cache and queue management |
| **Router** | 8003 | ‚úÖ Running | Task routing (no healthcheck) |
| **Firecrawl** | 8004 | ‚úÖ Running | Web scraping service |
| **Playwright Worker** | - | ‚úÖ Running | Browser automation |

### Host Services (Not Containers)
| Component | Port | Status | Purpose |
|-----------|------|--------|---------|
| **LM Studio** | 1234 | ‚úÖ Active | qwen3-next-80b model serving (host process) |
| **MLX Server** | 8000 | ‚ùå Not Running | Would run MLX models if started |


### Service Architecture & Workflow

```
User Request Flow:

    [Castle GUI :3000]
           ‚Üì
    [API Gateway :8080]
       /    |    \
      ‚Üì     ‚Üì     ‚Üì
[KB Service] [MLX Proxy :8001] [TechKnowledge :8002]
     ‚Üì              ‚Üì                    ‚Üì
[PostgreSQL]  [Host MLX :8000]    [PostgreSQL]
  pgvector      ‚Üì fallback ‚Üì        22 techs
            [LM Studio :1234]      702 specs
              qwen3-next-80b

Crawl Stack Flow:

    [Crawl Request] ‚Üí [Router :8003]
         ‚Üì                    ‚Üì
    Auth Required?       Simple Scrape?
         ‚Üì                    ‚Üì
    [Redis Queue]        [Firecrawl :8004]
         ‚Üì                    ‚Üì
    [Playwright Worker]  [Cloud API]
         ‚Üì                    ‚Üì
    [Authenticated Data] [Scraped Content]
```

### Functional Capabilities

#### API Gateway (`services/api/`)
- **Health Monitoring**: Real-time downstream service status
- **Authentication**: X-API-Key header validation
- **Service Routing**: Intelligent request distribution
- **Metrics Collection**: Prometheus endpoints
- **CORS Support**: Castle GUI integration

#### Knowledge Base Service (`services/kb/`)
- **Vector Storage**: PostgreSQL with pgvector extension
- **Embeddings**:
  - Primary: LM Studio nomic-embed-text-v1.5 (768 dims)
  - Fallback 1: OpenAI text-embedding-ada-002 (1536 dims)
  - Fallback 2: Gemini text-embedding-004 (768 dims)
- **Similarity Search**: Vector-based content retrieval
- **Async Operations**: High-performance asyncpg pooling

#### MLX Inference (`services/mlx/` + host)
- **Current Model**: qwen/qwen3-next-80b via LM Studio (port 1234)
- **Available Models**: foundation-sec-8b, qwen3-30b-a3b-instruct
- **Auto-Failover**: Seamless switch to LM Studio when primary unavailable
- **Proxy Pattern**: Docker container ‚Üí Host MLX/LM Studio
- **Response Transformation**: OpenAI format ‚Üî MLX format

#### TechKnowledge System (`services/techknowledge/`)
- **Knowledge Graph**: 22 technologies with full specifications
- **Rich Metadata**: 702 technical specifications preserved
- **REST API**: Query technologies, specifications, categories
- **Statistical Analysis**: Technology adoption metrics
- **PostgreSQL Backend**: Structured knowledge storage
- **Crawl Integration**: Automated documentation updates via crawl stack

#### Crawl Stack (`services/router/`, `services/firecrawl/`, `services/playwright_worker/`)
- **Intelligent Routing**: Router analyzes intent and URL patterns
- **Redis Queue**: Task management for Playwright jobs
- **Firecrawl Integration**: Cloud API with fc-b641c64dbb3b4962909c2f8f04c524ba
- **Playwright Worker**: Headless browser for authenticated scraping
- **Auto-Detection**: Identifies login/auth requirements automatically
- **Result Caching**: Redis-based result storage with TTL

### Quick Verification Commands

```bash
# Check all services health
make health

# Run smoke tests
make smoke-test

# Full verification suite
make verify

# View container status
docker ps

# Test API Gateway
curl http://localhost:8080/health

# Test MLX inference
curl -X POST http://localhost:8080/inference \
  -H "Content-Type: application/json" \
  -H "X-API-Key: dev-key-change-in-production" \
  -d '{"prompt": "What is 2+2?", "max_tokens": 50}'

# Test TechKnowledge
curl http://localhost:8002/stats

# Test Crawl Stack
bash scripts/verify_crawl_stack.sh

# Test Router health
curl http://localhost:8003/health

# Test Firecrawl service
curl http://localhost:8004/health

# Submit crawl task
curl -X POST http://localhost:8003/crawl \
  -H "Content-Type: application/json" \
  -d '{"url":"https://example.com","intent":"scrape"}'

# Access services
open http://localhost:3000  # Castle GUI
open http://localhost:8080/docs  # API docs
open http://localhost:8002/docs  # TechKnowledge API
```

### Environment Variables

| Variable | Required | Default | Purpose |
|----------|----------|---------|---------|
| OPENAI_API_KEY | No | - | KB embeddings (falls back to local) |
| FREEDOM_API_KEY | Yes | dev-key-change-in-production | API Gateway auth |
| POSTGRES_USER | Yes | freedom | Database credentials |
| POSTGRES_PASSWORD | Yes | freedom_dev | Database credentials |
| POSTGRES_DB | Yes | freedom_kb | Database name |

### Platform Status: FULL Functionality and workflow status based on functional testing and audited for verification

**Platform Operational Status (2025-09-22T08:10:00Z):**
- **Containers**: 10 running
- **Databases**: PostgreSQL with freedom_kb and techknowledge databases
- **Health Status**: 8 healthy, 1 unhealthy (Castle GUI), 1 no healthcheck (Router)
- **Primary Model**: qwen/qwen3-next-80b via LM Studio (port 1234)
- **Service Connectivity**: All ports exposed and accessible

### Detailed Service Verification Results

#### 1. Docker Infrastructure
- **Container Count**: 10 active containers
- **Health Status**: All containers reporting healthy
- **Network**: Bridge network `freedom_default` operational
- **Volume Persistence**: PostgreSQL data volume mounted and active
- **Restart Policy**: All services set to `unless-stopped`

#### 2. API Gateway Service (Port 8080)
- **Endpoint Verification**:
  - `/health`: Returns 200 with downstream service status
  - `/metrics`: Prometheus metrics exposed
  - `/docs`: FastAPI documentation available
  - `/inference`: Routes to MLX proxy service
- **Authentication**: X-API-Key header required for protected endpoints
- **Response Times**: ~3-7ms for health checks
- **Downstream Monitoring**: Real-time status of KB and MLX services

#### 3. Knowledge Base Service (Internal Port 8000)
- **Database Connection**: AsyncPG pool (5-25 connections)
- **Vector Operations**:
  - Embedding generation: OpenAI ada-002 or local fallback
  - Vector dimensions: 1536 (compatible with both modes)
  - Similarity search: pgvector cosine distance
- **Fallback Mode**: Deterministic local embeddings using SHA256 seed
- **Performance**: ~6ms health check response time

#### 4. MLX Proxy Service (Port 8001 ‚Üí 8000)
- **Proxy Configuration**:
  - Container port 8001 maps to internal 8000
  - Forwards to host MLX at `host.docker.internal:8000`
- **Health Status**: Reports `mlx_server_reachable: true`
- **Graceful Degradation**: Returns "degraded" when host MLX unavailable
- **Request Forwarding**: Transparent proxy for inference requests

#### 5. PostgreSQL Database (Port 5432)
- **Configuration**:
  - Image: `pgvector/pgvector:pg15`
  - Database: `freedom_kb`
  - User: `freedom`
  - Password: `freedom_dev`
- **Extensions**: pgvector installed and verified
- **Schema**: techknowledge tables migrated
- **Connection Pool**: Managed by KB service

#### 6. Castle GUI (Port 3000)
- **Framework**: Next.js 14.2.5 with React 18
- **Build Process**: Multi-stage Docker build
- **API Integration**: Configured for `localhost:8080`
- **Static Assets**: Optimized production build
- **Response**: Returns 200 OK on root path

#### 7. Host MLX Server (Port 8000)
- **Model**: NOT RUNNING (would use MLX models if started)
- **Server**: mlx-vlm server
- **Performance Metrics**:
  - Generation speed: 408+ tokens/second
  - Prompt processing: 450+ tokens/second
  - Peak memory: ~1.17GB
- **Endpoints**:
  - `/generate`: Text generation endpoint
  - `/health`: Server status
  - `/docs`: API documentation

### Verification Evidence

#### Health Check Output
```bash
$ make health
üîç Checking service health...
‚úÖ API Gateway: healthy (uptime: 8427s)
‚úÖ MLX proxy up
‚úÖ KB service up
‚úÖ Postgres up (accepting connections)
```

#### Container Status
```bash
$ docker ps
CONTAINER ID   IMAGE           STATUS         PORTS
freedom-api-1         Up (healthy)   0.0.0.0:8080->8080/tcp
freedom-kb-service-1  Up (healthy)   (internal only)
freedom-mlx-server-1  Up (healthy)   0.0.0.0:8001->8000/tcp
freedom-postgres-1    Up (healthy)   0.0.0.0:5432->5432/tcp
freedom-castle-gui-1  Up             0.0.0.0:3000->3000/tcp
```

#### API Gateway Health Response
```json
{
  "status": "healthy",
  "timestamp": "2025-09-19T20:02:10.942197",
  "uptime_seconds": 46.426398,
  "version": "1.0.0",
  "kb_service_status": "healthy",
  "kb_service_response_time_ms": 6.266,
  "mlx_service_status": "healthy",
  "mlx_service_response_time_ms": 7.155
}
```

#### MLX Generation Test
```json
{
  "text": "Hello! How can I help you today?",
  "model": "qwen/qwen3-next-80b",
  "usage": {
    "input_tokens": 16,
    "output_tokens": 10,
    "total_tokens": 26,
    "prompt_tps": 450.52,
    "generation_tps": 408.00,
    "peak_memory": 1.174
  }
}
```

### Testing & Validation

#### Smoke Test Results
- **MLX Service Health**: ‚úÖ PASS (mlx_server_reachable)
- **API Gateway Health**: ‚úÖ PASS (all services healthy)
- **KB Service Operation**: ‚úÖ PASS (with/without OpenAI)
- **PostgreSQL Connection**: ‚úÖ PASS (pgvector active)
- **Castle GUI Response**: ‚úÖ PASS (200 OK)

#### Integration Points Verified
1. **Castle GUI ‚Üí API Gateway**: CORS configured, requests routing
2. **API Gateway ‚Üí KB Service**: Internal network communication
3. **API Gateway ‚Üí MLX Proxy**: Service discovery working
4. **MLX Proxy ‚Üí Host MLX**: host.docker.internal resolution
5. **KB Service ‚Üí PostgreSQL**: Connection pooling active
6. **KB Service ‚Üí OpenAI/Local**: Fallback mechanism tested

### Audit Trail

#### Codex Audit Fixes (2025-09-19)
1. **Legacy api/routers**: Created stub files for compatibility
2. **migrate_router module**: Added BackwardsCompatibleRouter
3. **KB credentials**: Aligned with docker-compose defaults
4. **Makefile health checks**: Fixed KB service port access
5. **MLX smoke tests**: Updated for actual response fields
6. **KB OpenAI fallback**: Implemented local embedding mode

#### Platform Compliance
- **FREEDOM Prime Directive**: "If it doesn't run, it doesn't exist" ‚úÖ
- **Functional Reality**: All components executing and producing output
- **Verification Requirements**: EXECUTE ‚úÖ PROCESS ‚úÖ PRODUCE ‚úÖ INTEGRATE ‚úÖ DELIVER ‚úÖ

---

## ü§ñ Claude AI Integration (MCP Servers)

The FREEDOM platform includes advanced Model Context Protocol (MCP) servers for enhanced AI-assisted development with Claude Desktop and Claude Code.

### Available MCP Servers

| Server | Purpose | Key Features | Port/Location |
|--------|---------|--------------|---------------|
| **rag** | Semantic knowledge search | Natural language queries across 2,425 docs | Port 5003 |
| **postgres-freedom** | System database | Connection pooling, transaction support | Port 5432 |
| **techknowledge** | Specifications database | Raw tech specs, crawl data | Port 5432 |
| **docker** | Container management | Health monitoring, log analysis | Docker socket |
| **http-api** | API testing | Pre-configured auth, performance testing | Port 8080 |
| **redis** | Cache/queue management | Queue monitoring, cache operations | Port 6379 |

### Quick Start with Claude

```bash
# Install MCP servers (one-time setup)
cd mcp-servers/
npm install  # Install dependencies for custom servers

# Start required services
docker-compose up -d  # Start PostgreSQL, Redis, etc.
cd services/rag_chunker && python3 rag_api.py  # Start RAG API

# MCP servers auto-activate in Claude Desktop/Code
```

See [MCP_SETUP_GUIDE.md](documents/MCP_SETUP_GUIDE_20250921_1800.md) for detailed configuration instructions.

---

## ‚ö†Ô∏è Current Service States (As of 2025-09-22)

### Service Health
1. **Castle GUI** - Running, responds 200 OK, healthcheck reports unhealthy
2. **MLX host server** - Not running on port 8000
3. **LM Studio** - Running on port 1234, provides inference
4. **RAG System** - 3 chunks in database, 768-dim embeddings configured
5. **TechKnowledge** - 22 technologies, 702 specifications in database

---

## üóÑÔ∏è Database Operations

### Quick Database Access

```bash
# Query techknowledge database (702 specifications)
docker exec freedom-postgres-1 psql -U freedom -d techknowledge -c "SELECT name FROM technologies;"

# Query freedom_kb database
docker exec freedom-postgres-1 psql -U freedom -d freedom_kb -c "SELECT * FROM health_check;"

# Search specifications
docker exec freedom-postgres-1 psql -U freedom -d techknowledge -c "SELECT t.name, s.component_name FROM specifications s JOIN technologies t ON s.technology_id = t.id WHERE specification::text ILIKE '%mcp%';"

# Interactive shell
docker exec -it freedom-postgres-1 psql -U freedom -d techknowledge
```

**Note**: TechKnowledge service (port 8002) only provides `/health` endpoint. Use direct database queries for data access.

---

## üîÑ Container Persistence & Auto-Startup

The FREEDOM platform is configured for 24/7 operation with automatic recovery from system reboots.

### Persistence Configuration

| Mechanism | Purpose | Configuration | Status |
|-----------|---------|--------------|--------|
| **Docker Restart Policies** | Auto-restart on Docker start | `restart: unless-stopped` on all services | ‚úÖ Active |
| **macOS LaunchAgent** | Start containers after boot | `com.freedom.docker-startup` runs every 300s | ‚úÖ Installed |
| **Docker Desktop** | Auto-start on login | Added to macOS login items | ‚úÖ Configured |

---

## üìú License
MIT License ‚Äì see [LICENSE](LICENSE)

---

