#!/usr/bin/env python3
"""
GPU Accelerator for CCKS using MLX Framework
Leverages Apple Silicon GPU for vector operations and similarity search
"""

import sys
import os
import time
import numpy as np
from typing import List, Tuple, Optional

try:
    import mlx
    import mlx.core as mx
    MLX_AVAILABLE = True
except ImportError:
    MLX_AVAILABLE = False
    print("‚ö†Ô∏è  MLX not available, using CPU fallback")

class CCKSGPUAccelerator:
    """GPU acceleration for CCKS operations using MLX."""

    def __init__(self, dim: int = 768, use_gpu: bool = True):
        self.dim = dim
        self.use_gpu = use_gpu and MLX_AVAILABLE

        if self.use_gpu:
            # Set default device to GPU
            mx.set_default_device(mx.gpu)
            self.device = mx.gpu
            print(f"‚úÖ MLX GPU acceleration enabled (80 cores)")
        else:
            self.device = None
            print("‚ö†Ô∏è  Running in CPU mode")

    def compute_embeddings_batch(self, texts: List[str], model=None) -> np.ndarray:
        """
        Compute embeddings for a batch of texts using GPU.
        Note: This is a simulation - real implementation would use actual model.
        """
        if not self.use_gpu:
            # CPU fallback - simple random embeddings for demo
            return np.random.randn(len(texts), self.dim).astype(np.float32)

        # GPU accelerated version
        batch_size = len(texts)

        # Simulate text to embedding (in real usage, would use actual model)
        # Create random embeddings on GPU
        embeddings = mx.random.normal((batch_size, self.dim))

        # Normalize embeddings on GPU
        norms = mx.sqrt(mx.sum(embeddings * embeddings, axis=1, keepdims=True))
        embeddings = embeddings / norms

        # Convert back to numpy
        return np.array(embeddings)

    def cosine_similarity_batch(self, query: np.ndarray, corpus: np.ndarray) -> np.ndarray:
        """Compute cosine similarity between query and corpus using GPU."""
        if not self.use_gpu:
            # CPU fallback
            query_norm = query / np.linalg.norm(query)
            corpus_norm = corpus / np.linalg.norm(corpus, axis=1, keepdims=True)
            return np.dot(corpus_norm, query_norm)

        # GPU accelerated version
        query_mx = mx.array(query)
        corpus_mx = mx.array(corpus)

        # Normalize on GPU
        query_norm = query_mx / mx.sqrt(mx.sum(query_mx * query_mx))
        corpus_norms = mx.sqrt(mx.sum(corpus_mx * corpus_mx, axis=1, keepdims=True))
        corpus_norm = corpus_mx / corpus_norms

        # Compute similarity on GPU
        similarities = mx.matmul(corpus_norm, query_norm)

        return np.array(similarities)

    def top_k_similarity(self, query: np.ndarray, corpus: np.ndarray, k: int = 5) -> List[Tuple[int, float]]:
        """Find top-k most similar items using GPU."""
        similarities = self.cosine_similarity_batch(query, corpus)

        if self.use_gpu:
            # GPU accelerated sorting
            similarities_mx = mx.array(similarities)
            top_k_indices = mx.argsort(similarities_mx)[-k:][::-1]
            top_k_values = similarities_mx[top_k_indices]

            results = [(int(idx), float(val)) for idx, val in
                      zip(np.array(top_k_indices), np.array(top_k_values))]
        else:
            # CPU fallback
            top_k_indices = np.argsort(similarities)[-k:][::-1]
            results = [(int(idx), float(similarities[idx])) for idx in top_k_indices]

        return results

    def benchmark(self, num_queries: int = 100, corpus_size: int = 10000):
        """Benchmark GPU vs CPU performance."""
        print(f"\nüèÉ Benchmarking with {num_queries} queries on {corpus_size} items...")

        # Generate test data
        queries = np.random.randn(num_queries, self.dim).astype(np.float32)
        corpus = np.random.randn(corpus_size, self.dim).astype(np.float32)

        # GPU benchmark
        if self.use_gpu:
            start = time.perf_counter()
            for q in queries:
                _ = self.cosine_similarity_batch(q, corpus)
            gpu_time = time.perf_counter() - start
            gpu_qps = num_queries / gpu_time
            print(f"  GPU: {gpu_time:.3f}s ({gpu_qps:.1f} queries/sec)")

        # CPU benchmark (force CPU mode)
        original_gpu = self.use_gpu
        self.use_gpu = False

        start = time.perf_counter()
        for q in queries[:10]:  # Only 10 for CPU to avoid long wait
            _ = self.cosine_similarity_batch(q, corpus)
        cpu_time = (time.perf_counter() - start) * 10  # Extrapolate

        cpu_qps = num_queries / cpu_time
        print(f"  CPU: {cpu_time:.3f}s ({cpu_qps:.1f} queries/sec)")

        self.use_gpu = original_gpu

        if self.use_gpu and cpu_time > 0:
            speedup = cpu_time / gpu_time
            print(f"  üöÄ GPU Speedup: {speedup:.1f}x faster!")

    def stats(self):
        """Get GPU statistics."""
        stats = {
            "gpu_enabled": self.use_gpu,
            "framework": "MLX" if MLX_AVAILABLE else "NumPy",
            "device": str(self.device) if self.device else "CPU",
            "dimension": self.dim
        }

        if self.use_gpu:
            stats["gpu_cores"] = 80  # M3 Ultra
            stats["memory_bandwidth"] = "800 GB/s"  # M3 Ultra spec

        return stats


if __name__ == "__main__":
    print("üöÄ CCKS GPU Accelerator Test")
    print("-" * 40)

    accelerator = CCKSGPUAccelerator(dim=768)

    # Show stats
    stats = accelerator.stats()
    print(f"üìä Configuration:")
    for key, value in stats.items():
        print(f"  {key}: {value}")

    # Test embedding computation
    print("\n‚ö° Testing batch operations...")
    texts = ["Sample text 1", "Another example", "Third test"] * 10  # 30 texts

    start = time.perf_counter()
    embeddings = accelerator.compute_embeddings_batch(texts)
    embed_time = (time.perf_counter() - start) * 1000

    print(f"  Computed {len(texts)} embeddings in {embed_time:.2f}ms")
    print(f"  Rate: {len(texts) / (embed_time/1000):.1f} embeddings/sec")

    # Test similarity search
    print("\nüîç Testing similarity search...")
    query = embeddings[0]
    corpus = np.random.randn(5000, 768).astype(np.float32)

    start = time.perf_counter()
    top_results = accelerator.top_k_similarity(query, corpus, k=5)
    search_time = (time.perf_counter() - start) * 1000

    print(f"  Searched 5000 vectors in {search_time:.2f}ms")
    print(f"  Top match: idx={top_results[0][0]}, score={top_results[0][1]:.3f}")

    # Run benchmark
    accelerator.benchmark(num_queries=50, corpus_size=5000)

    print("\n‚ú® GPU acceleration ready for CCKS integration!")